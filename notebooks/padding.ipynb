{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8626ecf735a490e89d41f15420ccc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import random\n",
    "import string\n",
    "\n",
    "model_id = \"hugging-quants/Meta-Llama-3.1-8B-BNB-NF4-BF16\"\n",
    "# model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "logits_no_pad = model(\n",
    "    input_ids=torch.tensor([[tokenizer.bos_token_id, 100, 101, 102]]).cuda(),\n",
    "    attention_mask=torch.tensor([[1, 1, 1, 1]]).cuda(),\n",
    ").logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_size = 50\n",
    "logits_pad = model(\n",
    "    input_ids=torch.tensor(\n",
    "        [[tokenizer.bos_token_id] * (padding_size + 1) + [100, 101, 102]]\n",
    "    ).cuda(),\n",
    "    attention_mask=torch.tensor([[0] * padding_size + [1, 1, 1, 1]]).cuda(),\n",
    ").logits[0, padding_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004985138773918152"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_no_pad = logits_no_pad.softmax(dim=-1)\n",
    "probs_pad = logits_pad.softmax(dim=-1)\n",
    "(probs_no_pad - probs_pad).abs().max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15625\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token_id = tokenizer.encode(\"<|finetune_right_pad_id|>\")[-1]\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "prompt_str1 = \"\".join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "prompt_str2 = \"\".join(random.choices(string.ascii_letters + string.digits, k=20))\n",
    "padded_seqs = tokenizer(\n",
    "    [prompt_str1, prompt_str2],\n",
    "    padding=True,\n",
    "    padding_side=\"left\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "unpadded_seq = tokenizer(\n",
    "    prompt_str1,\n",
    "    padding=True,\n",
    "    padding_side=\"left\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "unpadded_logits = model(\n",
    "    input_ids=unpadded_seq.input_ids,\n",
    "    attention_mask=unpadded_seq.attention_mask,\n",
    ").logits[0]\n",
    "seq_len = unpadded_logits.shape[0]\n",
    "padded_logits0 = model(\n",
    "    input_ids=padded_seqs.input_ids,\n",
    "    attention_mask=padded_seqs.attention_mask,\n",
    ").logits[0, -seq_len:]\n",
    "print((unpadded_logits - padded_logits0).abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpadded_seqs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "padded_seqs[\"attention_mask\"][:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdpa'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config._attn_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpadded_seq[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004,\n",
       "         128000,     33,     15,     74,     40,    675,     47,     20,   1216],\n",
       "        [128000,     83,     53,     73,  23662,     80,     70,     53,     70,\n",
       "          78120,     88,  54978,     48,     86,     39,     15,     65,     57]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.encode(\"<|finetune_right_pad_id|>\")[-1]\n",
    "prompt_str1 = \"\".join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "prompt_str2 = \"\".join(random.choices(string.ascii_letters + string.digits, k=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seqs = tokenizer(\n",
    "    [prompt_str1, prompt_str2],\n",
    "    padding=True,\n",
    "    padding_side=\"left\",\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpadded_seq = tokenizer(\n",
    "    prompt_str1,\n",
    "    padding=True,\n",
    "    padding_side=\"left\",\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 128256]), torch.Size([9, 128256]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpadded_logits = model(**unpadded_seq).logits[0]\n",
    "seq_len = unpadded_logits.shape[0]\n",
    "padded_logits = model(**padded_seqs).logits[0, -seq_len:]\n",
    "unpadded_logits.shape, padded_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1250, 0.1875, 0.1562, 0.1250, 0.1719, 0.1406, 0.1250, 0.1562])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unpadded_logits - padded_logits).abs().max(dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_4d_causal_attention_mask_with_cache_position(\n",
    "    attention_mask: torch.Tensor,\n",
    "    sequence_length: int,\n",
    "    target_length: int,\n",
    "    dtype: torch.dtype,\n",
    "    device: torch.device,\n",
    "    cache_position: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a causal 4D mask of shape `(batch_size, 1, query_length, key_value_length)` from a 2D mask of shape\n",
    "    `(batch_size, key_value_length)`, or if the input `attention_mask` is already 4D, do nothing.\n",
    "\n",
    "    Args:\n",
    "        attention_mask (`torch.Tensor`):\n",
    "            A 2D attention mask of shape `(batch_size, key_value_length)` or a 4D attention mask of shape\n",
    "            `(batch_size, 1, query_length, key_value_length)`.\n",
    "        sequence_length (`int`):\n",
    "            The sequence length being processed.\n",
    "        target_length (`int`):\n",
    "            The target length: when generating with static cache, the mask should be as long as the static cache,\n",
    "            to account for the 0 padding, the part of the cache that is not filled yet.\n",
    "        dtype (`torch.dtype`):\n",
    "            The dtype to use for the 4D attention mask.\n",
    "        device (`torch.device`):\n",
    "            The device to plcae the 4D attention mask on.\n",
    "        cache_position (`torch.Tensor`):\n",
    "            Indices depicting the position of the input sequence tokens in the sequence.\n",
    "        batch_size (`torch.Tensor`):\n",
    "            Batch size.\n",
    "    \"\"\"\n",
    "    if attention_mask is not None and attention_mask.dim() == 4:\n",
    "        # In this case we assume that the mask comes already in inverted form and requires no inversion or slicing.\n",
    "        causal_mask = attention_mask\n",
    "    else:\n",
    "        min_dtype = torch.finfo(dtype).min\n",
    "        causal_mask = torch.full(\n",
    "            (sequence_length, target_length),\n",
    "            fill_value=min_dtype,\n",
    "            dtype=dtype,\n",
    "            device=device,\n",
    "        )\n",
    "        if sequence_length != 1:\n",
    "            causal_mask = torch.triu(causal_mask, diagonal=1)\n",
    "        causal_mask *= torch.arange(\n",
    "            target_length, device=device\n",
    "        ) > cache_position.reshape(-1, 1)\n",
    "        causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)\n",
    "        if attention_mask is not None:\n",
    "            causal_mask = (\n",
    "                causal_mask.clone()\n",
    "            )  # copy to contiguous memory for in-place edit\n",
    "            mask_length = attention_mask.shape[-1]\n",
    "            padding_mask = (\n",
    "                causal_mask[:, :, :, :mask_length] + attention_mask[:, None, None, :]\n",
    "            )\n",
    "            padding_mask = padding_mask == 0\n",
    "            causal_mask[:, :, :, :mask_length] = causal_mask[\n",
    "                :, :, :, :mask_length\n",
    "            ].masked_fill(padding_mask, min_dtype)\n",
    "\n",
    "    return causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00, -3.3895e+38, -3.3895e+38],\n",
       "          [ 0.0000e+00,  0.0000e+00, -3.3895e+38],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[-3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
       "          [-3.3895e+38,  0.0000e+00, -3.3895e+38],\n",
       "          [-3.3895e+38,  0.0000e+00,  0.0000e+00]]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_prepare_4d_causal_attention_mask_with_cache_position(\n",
    "    attention_mask=torch.tensor([[1, 1, 1], [0, 1, 1]]),\n",
    "    sequence_length=3,\n",
    "    target_length=3,\n",
    "    dtype=torch.bfloat16,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    cache_position=torch.tensor([0, 1, 2]),\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.bfloat16\n",
    "dtype_min = torch.finfo(dtype).min\n",
    "pad_size = 1_000_000\n",
    "unpadded_weights = torch.tensor([1e-10, 1.1e-10], dtype=dtype, device=\"cuda\")\n",
    "padded_weights = torch.tensor(\n",
    "    [dtype_min] * pad_size + [1e-10, 1.1e-10], dtype=dtype, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpadded_probs = torch.softmax(unpadded_weights, dim=-1)\n",
    "padded_probs = torch.softmax(padded_weights, dim=-1)[-2:]\n",
    "unpadded_probs == padded_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpadded_probs.shape, padded_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 / 16 questions have the same length\n"
     ]
    }
   ],
   "source": [
    "from cot_probing.diverse_combinations import load_and_process_file\n",
    "from cot_probing import DATA_DIR\n",
    "from cot_probing.vis import visualize_tokens_html\n",
    "from IPython.display import HTML\n",
    "\n",
    "yes_qs = load_and_process_file(DATA_DIR / \"diverse_yes.txt\")\n",
    "no_qs = load_and_process_file(DATA_DIR / \"diverse_no.txt\")\n",
    "yes_tokenized_qs = [tokenizer.encode(q, add_special_tokens=False) for q in yes_qs]\n",
    "no_tokenized_qs = [tokenizer.encode(q, add_special_tokens=False) for q in no_qs]\n",
    "n_all_questions = len(yes_tokenized_qs)\n",
    "n_same_length = 0\n",
    "for tok_q_yes, tok_q_no in zip(yes_tokenized_qs, no_tokenized_qs):\n",
    "    if len(tok_q_yes) == len(tok_q_no):\n",
    "        n_same_length += 1\n",
    "    else:\n",
    "        print(len(tok_q_yes))\n",
    "        display(HTML(visualize_tokens_html(tok_q_yes, tokenizer)))\n",
    "        print(len(tok_q_no))\n",
    "        display(HTML(visualize_tokens_html(tok_q_no, tokenizer)))\n",
    "print(f\"{n_same_length} / {n_all_questions} questions have the same length\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
